From e23596b48113e5bdd392dcb701dfb476f20033f8 Mon Sep 17 00:00:00 2001
From: Jianxiong Pan <jianxiong.pan@amlogic.com>
Date: Tue, 23 May 2023 13:37:52 +0800
Subject: [PATCH] mm: port lowmemorykiller for 5.15+P. [1/2]

PD#SWPL-124928

Problem:
Android P no LMKD.

Solution:
add statistics for free file cma and more.

Verify:
local.

Change-Id: If31f74666d97b9e42627e7d7fff693b52e0fbc2e
Signed-off-by: Jianxiong Pan <jianxiong.pan@amlogic.com>
---
 include/linux/mm_inline.h | 40 +++++++++++++++++++++++++++++++++++++++
 include/linux/mmzone.h    |  8 ++++++++
 include/linux/sched.h     |  8 ++++++++
 mm/vmscan.c               | 12 ++++++++++++
 mm/vmstat.c               |  8 ++++++++
 5 files changed, 76 insertions(+)

diff --git a/include/linux/mm_inline.h b/include/linux/mm_inline.h
index 4a0cb6988014..003acbb9d3a0 100644
--- a/include/linux/mm_inline.h
+++ b/include/linux/mm_inline.h
@@ -5,6 +5,9 @@
 #include <linux/huge_mm.h>
 #include <linux/swap.h>
 #include <linux/string.h>
+#ifdef CONFIG_AMLOGIC_LMK
+#include <linux/page-isolation.h>
+#endif
 
 /**
  * page_is_file_lru - should the page be on a file LRU or anon LRU?
@@ -320,6 +323,11 @@ static inline bool lru_gen_del_page(struct lruvec *lruvec, struct page *page, bo
 static __always_inline void add_page_to_lru_list(struct page *page,
 				struct lruvec *lruvec)
 {
+#ifdef CONFIG_AMLOGIC_LMK
+	int nr_pages = thp_nr_pages(page);
+	int num = NR_INACTIVE_ANON_CMA - NR_ZONE_INACTIVE_ANON;
+	int migrate_type = 0;
+#endif /* CONFIG_AMLOGIC_LMK */
 	enum lru_list lru = page_lru(page);
 
 	if (lru_gen_add_page(lruvec, page, false))
@@ -327,11 +335,23 @@ static __always_inline void add_page_to_lru_list(struct page *page,
 
 	update_lru_size(lruvec, lru, page_zonenum(page), thp_nr_pages(page));
 	list_add(&page->lru, &lruvec->lists[lru]);
+
+#ifdef CONFIG_AMLOGIC_LMK
+	migrate_type = get_pageblock_migratetype(page);
+	if (is_migrate_cma(migrate_type) || is_migrate_isolate(migrate_type))
+		__mod_zone_page_state(page_zone(page),
+				      NR_ZONE_LRU_BASE + lru + num, nr_pages);
+#endif /* CONFIG_AMLOGIC_LMK */
 }
 
 static __always_inline void add_page_to_lru_list_tail(struct page *page,
 				struct lruvec *lruvec)
 {
+#ifdef CONFIG_AMLOGIC_LMK
+	int nr_pages = thp_nr_pages(page);
+	int num = NR_INACTIVE_ANON_CMA - NR_ZONE_INACTIVE_ANON;
+	int migrate_type = 0;
+#endif /* CONFIG_AMLOGIC_LMK */
 	enum lru_list lru = page_lru(page);
 
 	if (lru_gen_add_page(lruvec, page, true))
@@ -339,17 +359,37 @@ static __always_inline void add_page_to_lru_list_tail(struct page *page,
 
 	update_lru_size(lruvec, lru, page_zonenum(page), thp_nr_pages(page));
 	list_add_tail(&page->lru, &lruvec->lists[lru]);
+
+#ifdef CONFIG_AMLOGIC_LMK
+	migrate_type = get_pageblock_migratetype(page);
+	if (is_migrate_cma(migrate_type) || is_migrate_isolate(migrate_type))
+		__mod_zone_page_state(page_zone(page),
+				      NR_ZONE_LRU_BASE + lru + num, nr_pages);
+#endif /* CONFIG_AMLOGIC_LMK */
 }
 
 static __always_inline void del_page_from_lru_list(struct page *page,
 				struct lruvec *lruvec)
 {
+#ifdef CONFIG_AMLOGIC_LMK
+	int nr_pages = thp_nr_pages(page);
+	int num = NR_INACTIVE_ANON_CMA - NR_ZONE_INACTIVE_ANON;
+	int migrate_type = 0;
+#endif /* CONFIG_AMLOGIC_LMK */
+
 	if (lru_gen_del_page(lruvec, page, false))
 		return;
 
 	list_del(&page->lru);
 	update_lru_size(lruvec, page_lru(page), page_zonenum(page),
 			-thp_nr_pages(page));
+
+#ifdef CONFIG_AMLOGIC_LMK
+	migrate_type = get_pageblock_migratetype(page);
+	if (is_migrate_cma(migrate_type) || is_migrate_isolate(migrate_type))
+		__mod_zone_page_state(page_zone(page),
+				      NR_ZONE_LRU_BASE + page_lru(page) + num, -nr_pages);
+#endif /* CONFIG_AMLOGIC_LMK */
 }
 
 #ifdef CONFIG_ANON_VMA_NAME
diff --git a/include/linux/mmzone.h b/include/linux/mmzone.h
index 30b7c36d4b43..4d38e7d04a6e 100644
--- a/include/linux/mmzone.h
+++ b/include/linux/mmzone.h
@@ -177,6 +177,14 @@ enum zone_stat_item {
 	NR_BOUNCE,
 	NR_ZSPAGES,		/* allocated in zsmalloc */
 	NR_FREE_CMA_PAGES,
+#ifdef CONFIG_AMLOGIC_LMK
+	NR_INACTIVE_ANON_CMA,	/* must match order of LRU_[IN]ACTIVE */
+	NR_ACTIVE_ANON_CMA,
+	NR_INACTIVE_FILE_CMA,
+	NR_ACTIVE_FILE_CMA,
+	NR_UNEVICTABLE_FILE_CMA,
+	NR_CMA_ISOLATED,	/* cma isolate */
+#endif
 	NR_VM_ZONE_STAT_ITEMS };
 
 enum node_stat_item {
diff --git a/include/linux/sched.h b/include/linux/sched.h
index 2bbce8564e9b..d4f8ad582cb9 100644
--- a/include/linux/sched.h
+++ b/include/linux/sched.h
@@ -1787,6 +1787,9 @@ static __always_inline bool is_percpu_thread(void)
 #define PFA_SPEC_IB_DISABLE		5	/* Indirect branch speculation restricted */
 #define PFA_SPEC_IB_FORCE_DISABLE	6	/* Indirect branch speculation permanently restricted */
 #define PFA_SPEC_SSB_NOEXEC		7	/* Speculative Store Bypass clear on execve() */
+#ifdef CONFIG_AMLOGIC_LMK
+#define PFA_LMK_WAITING			8	/* Lowmemorykiller is waiting */
+#endif
 
 #define TASK_PFA_TEST(name, func)					\
 	static inline bool task_##func(struct task_struct *p)		\
@@ -1829,6 +1832,11 @@ TASK_PFA_CLEAR(SPEC_IB_DISABLE, spec_ib_disable)
 TASK_PFA_TEST(SPEC_IB_FORCE_DISABLE, spec_ib_force_disable)
 TASK_PFA_SET(SPEC_IB_FORCE_DISABLE, spec_ib_force_disable)
 
+#ifdef CONFIG_AMLOGIC_LMK
+TASK_PFA_TEST(LMK_WAITING, lmk_waiting)
+TASK_PFA_SET(LMK_WAITING, lmk_waiting)
+#endif
+
 static inline void
 current_restore_flags(unsigned long orig_flags, unsigned long flags)
 {
diff --git a/mm/vmscan.c b/mm/vmscan.c
index dbf3bb871b02..5c44c3789633 100644
--- a/mm/vmscan.c
+++ b/mm/vmscan.c
@@ -1988,6 +1988,11 @@ static unsigned long isolate_lru_pages(unsigned long nr_to_scan,
 	unsigned long skipped = 0;
 	unsigned long scan, total_scan, nr_pages;
 	LIST_HEAD(pages_skipped);
+#ifdef CONFIG_AMLOGIC_LMK
+	int num = NR_INACTIVE_ANON_CMA - NR_ZONE_INACTIVE_ANON +
+		  NR_ZONE_LRU_BASE;
+	int migrate_type = 0;
+#endif /* CONFIG_AMLOGIC_LMK */
 
 	total_scan = 0;
 	scan = 0;
@@ -2038,6 +2043,13 @@ static unsigned long isolate_lru_pages(unsigned long nr_to_scan,
 		nr_taken += nr_pages;
 		nr_zone_taken[page_zonenum(page)] += nr_pages;
 		move_to = dst;
+	#ifdef CONFIG_AMLOGIC_LMK
+		migrate_type = get_pageblock_migratetype(page);
+		if (is_migrate_cma(migrate_type) ||
+		    is_migrate_isolate(migrate_type))
+			__mod_zone_page_state(page_zone(page),
+					      lru + num, -nr_pages);
+	#endif /* CONFIG_AMLOGIC_LMK */
 move:
 		list_move(&page->lru, move_to);
 	}
diff --git a/mm/vmstat.c b/mm/vmstat.c
index 4349599d0209..9b8e45d808bf 100644
--- a/mm/vmstat.c
+++ b/mm/vmstat.c
@@ -1178,6 +1178,14 @@ const char * const vmstat_text[] = {
 	"nr_bounce",
 	"nr_zspages",
 	"nr_free_cma",
+#ifdef CONFIG_AMLOGIC_LMK
+	"nr_inactive_anon_cma",
+	"nr_active_anon_cma",
+	"nr_inactive_file_cma",
+	"nr_active_file_cma",
+	"nr_unevictable_cma",
+	"nr_isolated_cma",
+#endif
 
 	/* enum numa_stat_item counters */
 #ifdef CONFIG_NUMA
-- 
2.25.1

